{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "if gpu:\n",
    "  # only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpu[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpu), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xAcc</th>\n",
       "      <th>yAcc</th>\n",
       "      <th>zAcc</th>\n",
       "      <th>xGyro</th>\n",
       "      <th>yGyro</th>\n",
       "      <th>zGyro</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.99</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-7.28</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>-3.23</td>\n",
       "      <td>2.62</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.51</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-6.93</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-6.35</td>\n",
       "      <td>4.64</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.22</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-6.73</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-5.49</td>\n",
       "      <td>3.85</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.34</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-6.80</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>0.67</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.49</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96795</th>\n",
       "      <td>7.30</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-4.58</td>\n",
       "      <td>18.19</td>\n",
       "      <td>3.60</td>\n",
       "      <td>-35.77</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96796</th>\n",
       "      <td>7.39</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-5.05</td>\n",
       "      <td>20.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-34.55</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96797</th>\n",
       "      <td>7.52</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-5.82</td>\n",
       "      <td>22.58</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-28.02</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96798</th>\n",
       "      <td>7.58</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>-6.31</td>\n",
       "      <td>19.47</td>\n",
       "      <td>2.44</td>\n",
       "      <td>-22.52</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96799</th>\n",
       "      <td>7.56</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>-5.89</td>\n",
       "      <td>15.56</td>\n",
       "      <td>3.91</td>\n",
       "      <td>-19.23</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96800 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xAcc  yAcc  zAcc  xGyro  yGyro  zGyro  label\n",
       "0      6.99 -0.57 -7.28  -2.75  -3.23   2.62   fall\n",
       "1      6.51 -0.75 -6.93  -0.67  -6.35   4.64   fall\n",
       "2      6.22 -0.63 -6.73   0.79  -5.49   3.85   fall\n",
       "3      6.34 -0.62 -6.80   1.59  -2.26   0.67   fall\n",
       "4      6.49 -0.39 -6.60   0.67  -0.24  -1.10   fall\n",
       "...     ...   ...   ...    ...    ...    ...    ...\n",
       "96795  7.30 -1.16 -4.58  18.19   3.60 -35.77  light\n",
       "96796  7.39 -0.37 -5.05  20.08   0.06 -34.55  light\n",
       "96797  7.52 -1.46 -5.82  22.58   0.12 -28.02  light\n",
       "96798  7.58 -2.14 -6.31  19.47   2.44 -22.52  light\n",
       "96799  7.56 -1.90 -5.89  15.56   3.91 -19.23  light\n",
       "\n",
       "[96800 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"..\\data3.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_resampling(data, seed=1218):\n",
    "    new_data = data.drop(\"label\",axis=1).to_numpy().reshape(-1, 400, 6)\n",
    "    labels = np.array(data.label.iloc[np.arange(0,data.shape[0], 400)])\n",
    "\n",
    "    sm = SMOTE(random_state=seed)\n",
    "    y = labels\n",
    "    X, y = sm.fit_resample(new_data.reshape(-1, 400*6), y)\n",
    "\n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train.reshape(-1, 400*6))\n",
    "    X_test = scaler.fit_transform(X_test.reshape(-1, 400*6))\n",
    "\n",
    "    # reshape\n",
    "    X_train = X_train.reshape(-1, 400, 6)\n",
    "    X_test = X_test.reshape(-1, 400, 6)\n",
    "    input_shape = X_train.shape[1:]\n",
    "    seq_len, n_features = input_shape\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(np.unique(y_train))\n",
    "    y_train = le.transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=7)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=7)\n",
    "\n",
    "    X_train = X_train.reshape(-1, seq_len, n_features) \n",
    "    X_test = X_test.reshape(-1, seq_len, n_features)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = split_resampling(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362, 400, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{Neural Network Architecture: First CNN} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN neural network is designed for the classification of human daily activities and fall behaviors. It is a relatively simple architecture with convolutional and fully connected layers. The network structure is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
    "\\\\\n",
    "2. & \\text{Convolution Layer:} \\\\\n",
    "   & \\text{Contains 32 filters with a kernel size of 3 and uses the ReLU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Flatten Layer:} \\\\\n",
    "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "5. & \\text{Fully Connected Layer 1:} \\\\\n",
    "   & \\text{Consists of 64 neurons with ReLU activation.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Fully Connected Layer 2:} \\\\\n",
    "   & \\text{The output layer consists of 7 neurons with sigmoid activation, providing class probabilities.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The First Model is trained using an appropriate optimizer, and the loss function is categorical cross-entropy. The performance of the model can be evaluated based on metrics such as accuracy.\n",
    "\n",
    "This simple First Model neural network is designed to classify human activities and fall behaviors effectively by extracting basic features from accelerometer and gyroscope data and producing class probabilities using a sigmoid activation function in the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(7, activation='sigmoid')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 398, 32)           608       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 199, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6368)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                407616    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 408,679\n",
      "Trainable params: 408,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "first_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 13s 52ms/step - loss: 1.0277 - accuracy: 0.6188 - val_loss: 0.6862 - val_accuracy: 0.7851\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1683 - accuracy: 0.9558 - val_loss: 0.3482 - val_accuracy: 0.8595\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9779 - val_loss: 0.1046 - val_accuracy: 0.9504\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 0.0880 - val_accuracy: 0.9669\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9752\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9752\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9752\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9752\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9752\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9752\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9752\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9752\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9752\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.3486e-04 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9752\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.5551e-04 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9752\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.8521e-04 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9752\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.2996e-04 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9752\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.7674e-04 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9752\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.2926e-04 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9752\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.8563e-04 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9752\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.4656e-04 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9752\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.1252e-04 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9752\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.8137e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.5405e-04 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9752\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.2704e-04 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9752\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.0487e-04 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9752\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.8143e-04 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9752\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.6180e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.4323e-04 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.2582e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.1111e-04 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9752\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.9671e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.8408e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7033e-04 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9752\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.5805e-04 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9752\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.4793e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3802e-04 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2851e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1973e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1194e-04 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9752\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.0387e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.9613e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.8907e-04 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9752\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.8247e-04 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9752\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.7619e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.7086e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.6489e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5898e-04 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9752\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5498e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4941e-04 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24d7f980c10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05871253460645676, 0.9752066135406494]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-HE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{Neural Network Architecture: CNN-HE (Convolutional Neural Network with Heuristic Enhancements)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN-HE neural network is designed for the classification of human daily activities and fall behaviors. It utilizes convolutional layers and heuristic enhancements to improve accuracy in fall detection. The network structure consists of the following layers:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and inputs them into the convolution layer and bidirectional LSTM layer, respectively.} \\\\\n",
    "\\\\\n",
    "2. & \\text{Convolution Layer 1:} \\\\\n",
    "   & \\text{Performs 1D convolution with 32 filters, each with a kernel size of 5 and ReLU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer 1:} \\\\\n",
    "   & \\text{Applies max-pooling with a pool size of 2 to perform subsampling.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Convolution Layer 2:} \\\\\n",
    "   & \\text{Performs 1D convolution with 64 filters, each with a kernel size of 5 and ReLU activation function.} \\\\\n",
    "\\\\\n",
    "5. & \\text{MaxPooling Layer 2:} \\\\\n",
    "   & \\text{Applies max-pooling with a pool size of 2 to perform subsampling.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Flatten Layer:} \\\\\n",
    "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "7. & \\text{Fully Connected Layer 1:} \\\\\n",
    "   & \\text{Consists of 512 neurons with ReLU activation function.} \\\\\n",
    "\\\\\n",
    "8. & \\text{Fully Connected Layer 2:} \\\\\n",
    "   & \\text{Consists of 7 neurons with softmax activation, which produces the final classification probabilities for 7 classes.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The network is trained using the Adam optimizer with a categorical cross-entropy loss function. During training, the model is trained for 70 epochs with a batch size of 64. The model's performance is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
    "\n",
    "This CNN-HE neural network is designed to effectively classify human activities and fall behaviors by extracting meaningful features from accelerometer and gyroscope data and utilizing heuristic enhancements to improve the accuracy of fall detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "6/6 [==============================] - 2s 223ms/step - loss: 2.3598 - accuracy: 0.4033 - val_loss: 1.9100 - val_accuracy: 0.2810\n",
      "Epoch 2/70\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8776 - accuracy: 0.7017 - val_loss: 0.6274 - val_accuracy: 0.8678\n",
      "Epoch 3/70\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3119 - accuracy: 0.9641 - val_loss: 0.3448 - val_accuracy: 0.8926\n",
      "Epoch 4/70\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1115 - accuracy: 0.9751 - val_loss: 0.1847 - val_accuracy: 0.9504\n",
      "Epoch 5/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0410 - accuracy: 0.9917 - val_loss: 0.1053 - val_accuracy: 0.9587\n",
      "Epoch 6/70\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9504\n",
      "Epoch 7/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9587\n",
      "Epoch 8/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9504\n",
      "Epoch 9/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9504\n",
      "Epoch 10/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.2641e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9587\n",
      "Epoch 11/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.6219e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9587\n",
      "Epoch 12/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.2867e-04 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9587\n",
      "Epoch 13/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.5395e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9587\n",
      "Epoch 14/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.9596e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9587\n",
      "Epoch 15/70\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.5083e-04 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9587\n",
      "Epoch 16/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.1565e-04 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9587\n",
      "Epoch 17/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8635e-04 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9587\n",
      "Epoch 18/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6141e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9587\n",
      "Epoch 19/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.3989e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9587\n",
      "Epoch 20/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.1974e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9587\n",
      "Epoch 21/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0113e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9587\n",
      "Epoch 22/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.8403e-04 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9587\n",
      "Epoch 23/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.6686e-04 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9587\n",
      "Epoch 24/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.5345e-04 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9587\n",
      "Epoch 25/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4098e-04 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9587\n",
      "Epoch 26/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2799e-04 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9587\n",
      "Epoch 27/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.1725e-04 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9587\n",
      "Epoch 28/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0657e-04 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9587\n",
      "Epoch 29/70\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.9642e-04 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9587\n",
      "Epoch 30/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.8515e-04 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9587\n",
      "Epoch 31/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7673e-04 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9587\n",
      "Epoch 32/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.6806e-04 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9587\n",
      "Epoch 33/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.6136e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9587\n",
      "Epoch 34/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.5310e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9587\n",
      "Epoch 35/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.4707e-04 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9587\n",
      "Epoch 36/70\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.3963e-04 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9587\n",
      "Epoch 37/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.3388e-04 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9587\n",
      "Epoch 38/70\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.2848e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9669\n",
      "Epoch 39/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.2260e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9669\n",
      "Epoch 40/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.1821e-04 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9669\n",
      "Epoch 41/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.1338e-04 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9669\n",
      "Epoch 42/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0840e-04 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9669\n",
      "Epoch 43/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0424e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9669\n",
      "Epoch 44/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0048e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9669\n",
      "Epoch 45/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.6479e-05 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9669\n",
      "Epoch 46/70\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.2999e-05 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9669\n",
      "Epoch 47/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.9193e-05 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9669\n",
      "Epoch 48/70\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.5794e-05 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9669\n",
      "Epoch 49/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.2749e-05 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9669\n",
      "Epoch 50/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.9797e-05 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9669\n",
      "Epoch 51/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.6810e-05 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9669\n",
      "Epoch 52/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.4325e-05 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9669\n",
      "Epoch 53/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.1867e-05 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9669\n",
      "Epoch 54/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9285e-05 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9669\n",
      "Epoch 55/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.6932e-05 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9669\n",
      "Epoch 56/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.4714e-05 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9669\n",
      "Epoch 57/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.2647e-05 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9669\n",
      "Epoch 58/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.0715e-05 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9669\n",
      "Epoch 59/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.8641e-05 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9669\n",
      "Epoch 60/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.7066e-05 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9669\n",
      "Epoch 61/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.5328e-05 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9669\n",
      "Epoch 62/70\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.3429e-05 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9669\n",
      "Epoch 63/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.1896e-05 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9669\n",
      "Epoch 64/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.0494e-05 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9669\n",
      "Epoch 65/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.8807e-05 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9669\n",
      "Epoch 66/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.7528e-05 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9669\n",
      "Epoch 67/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.6241e-05 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9669\n",
      "Epoch 68/70\n",
      "6/6 [==============================] - ETA: 0s - loss: 4.6496e-05 - accuracy: 1.00 - 0s 14ms/step - loss: 4.4881e-05 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9669\n",
      "Epoch 69/70\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3633e-05 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9669\n",
      "Epoch 70/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.2484e-05 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ef833e340>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_he = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=5, activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(64, kernel_size=5, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_he.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_he.fit(X_train, y_train, epochs=70, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-3B3Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{NN Architecture: CNN-3B3Conv (Convolutional Neural Network with Three Blocks of Three Convolutions)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN-3B3Conv neural network is designed for the classification of human daily activities and fall behaviors. It consists of three blocks, each containing three 1D convolutional layers with ReLU activation functions. The network structure is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
    "\\\\\n",
    "2. & \\text{Block 1:} \\\\\n",
    "   & \\text{Contains three 1D convolutional layers with 128 filters each and kernel sizes of 4. Each convolutional layer uses the ReLU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer 1:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Block 2:} \\\\\n",
    "   & \\text{Similar to Block 1, contains three 1D convolutional layers with 128 filters each and kernel sizes of 3. All layers use ReLU activation functions.} \\\\\n",
    "\\\\\n",
    "5. & \\text{MaxPooling Layer 2:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Flatten Layer:} \\\\\n",
    "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "7. & \\text{Fully Connected Layer 1:} \\\\\n",
    "   & \\text{Consists of 128 neurons with ReLU activation.} \\\\\n",
    "\\\\\n",
    "8. & \\text{Dropout Layer:} \\\\\n",
    "   & \\text{Applies dropout with a probability of 0.5 to reduce overfitting.} \\\\\n",
    "\\\\\n",
    "9. & \\text{Fully Connected Layer 2:} \\\\\n",
    "   & \\text{Contains 64 neurons with ReLU activation.} \\\\\n",
    "\\\\\n",
    "10. & \\text{Fully Connected Layer 3:} \\\\\n",
    "    & \\text{The output layer consists of 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN-3B3Conv model is trained using the Adam optimizer with categorical cross-entropy loss. During training, the model is trained for 20 epochs with a batch size of 64. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
    "\n",
    "This CNN-3B3Conv neural network is designed to classify human activities and fall behaviors effectively by leveraging three blocks of three convolutional layers to capture and extract relevant features from accelerometer and gyroscope data. The dropout layer helps prevent overfitting, enhancing the model's generalization ability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 224ms/step - loss: 1.8915 - accuracy: 0.2707 - val_loss: 1.4394 - val_accuracy: 0.6694\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.2125 - accuracy: 0.5856 - val_loss: 0.8283 - val_accuracy: 0.7603\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.7969 - accuracy: 0.7017 - val_loss: 0.5928 - val_accuracy: 0.8512\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.5237 - accuracy: 0.7928 - val_loss: 0.4383 - val_accuracy: 0.8760\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.3553 - accuracy: 0.8591 - val_loss: 0.4250 - val_accuracy: 0.8760\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.2094 - accuracy: 0.9392 - val_loss: 0.2541 - val_accuracy: 0.9174\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1785 - accuracy: 0.9392 - val_loss: 0.3014 - val_accuracy: 0.8843\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1531 - accuracy: 0.9503 - val_loss: 0.2131 - val_accuracy: 0.9339\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0925 - accuracy: 0.9751 - val_loss: 0.1242 - val_accuracy: 0.9587\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0624 - accuracy: 0.9834 - val_loss: 0.1337 - val_accuracy: 0.9587\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.1949 - val_accuracy: 0.9421\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0503 - accuracy: 0.9862 - val_loss: 0.1856 - val_accuracy: 0.9669\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0314 - accuracy: 0.9862 - val_loss: 0.2174 - val_accuracy: 0.9587\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0416 - accuracy: 0.9862 - val_loss: 0.1986 - val_accuracy: 0.9421\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0518 - accuracy: 0.9834 - val_loss: 0.1888 - val_accuracy: 0.9421\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0335 - accuracy: 0.9890 - val_loss: 0.1471 - val_accuracy: 0.9669\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0460 - accuracy: 0.9890 - val_loss: 0.3576 - val_accuracy: 0.9008\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0417 - accuracy: 0.9890 - val_loss: 0.2213 - val_accuracy: 0.9421\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0344 - accuracy: 0.9917 - val_loss: 0.1959 - val_accuracy: 0.9421\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.1954 - val_accuracy: 0.9504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f22940a30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_3B3Conv = models.Sequential([\n",
    "    layers.Conv1D(128, kernel_size=4, activation='relu', input_shape=input_shape),\n",
    "    layers.Conv1D(128, kernel_size=4, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "    ])\n",
    "\n",
    "CNN_3B3Conv.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "CNN_3B3Conv.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN EDU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{Neural Network Architecture: CNN-EDU (Convolutional Neural Network with Educational Enhancements)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN-EDU neural network is designed for the classification of human daily activities and fall behaviors. It features an architecture with multiple convolutional layers and educational enhancements to improve its performance. The network structure is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
    "\\\\\n",
    "2. & \\text{Convolution Layer 1:} \\\\\n",
    "   & \\text{Contains 16 filters with a kernel size of 5 and uses the ReLU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer 1:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Convolution Layer 2:} \\\\\n",
    "   & \\text{Consists of 32 filters with a kernel size of 5 and employs ReLU activation.} \\\\\n",
    "\\\\\n",
    "5. & \\text{MaxPooling Layer 2:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Convolution Layer 3:} \\\\\n",
    "   & \\text{Features 64 filters with a kernel size of 5 and ReLU activation.} \\\\\n",
    "\\\\\n",
    "7. & \\text{MaxPooling Layer 3:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "8. & \\text{Convolution Layer 4:} \\\\\n",
    "   & \\text{Incorporates 128 filters with a kernel size of 5 and ReLU activation.} \\\\\n",
    "\\\\\n",
    "9. & \\text{MaxPooling Layer 4:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "10. & \\text{Flatten Layer:} \\\\\n",
    "    & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "11. & \\text{Fully Connected Layer 1:} \\\\\n",
    "    & \\text{Consists of 128 neurons with ReLU activation.} \\\\\n",
    "\\\\\n",
    "12. & \\text{Dropout Layer:} \\\\\n",
    "    & \\text{Applies dropout with a probability of 0.5 to mitigate overfitting.} \\\\\n",
    "\\\\\n",
    "13. & \\text{Fully Connected Layer 2:} \\\\\n",
    "    & \\text{Contains 64 neurons with ReLU activation.} \\\\\n",
    "\\\\\n",
    "14. & \\text{Fully Connected Layer 3:} \\\\\n",
    "    & \\text{The output layer consists of 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN-EDU model is trained using the Adam optimizer with categorical cross-entropy loss. During training, the model is trained for 100 epochs with a batch size of 16. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
    "\n",
    "This CNN-EDU neural network leverages multiple convolutional layers and educational enhancements to effectively classify human activities and fall behaviors by extracting meaningful features from accelerometer and gyroscope data while reducing overfitting through dropout regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.7035 - accuracy: 0.3260 - val_loss: 1.0621 - val_accuracy: 0.7025\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1.0431 - accuracy: 0.5580 - val_loss: 0.6676 - val_accuracy: 0.7851\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6129 - accuracy: 0.7541 - val_loss: 0.4409 - val_accuracy: 0.8430\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4159 - accuracy: 0.8481 - val_loss: 0.4282 - val_accuracy: 0.8760\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4067 - accuracy: 0.8591 - val_loss: 0.4576 - val_accuracy: 0.7851\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.3326 - accuracy: 0.9006 - val_loss: 0.2293 - val_accuracy: 0.9339\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.1728 - accuracy: 0.9448 - val_loss: 0.1903 - val_accuracy: 0.9421\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.1556 - accuracy: 0.9365 - val_loss: 0.2533 - val_accuracy: 0.8512\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.1681 - accuracy: 0.9392 - val_loss: 0.1577 - val_accuracy: 0.9174\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0738 - accuracy: 0.9834 - val_loss: 0.2303 - val_accuracy: 0.9339\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0807 - accuracy: 0.9696 - val_loss: 0.2050 - val_accuracy: 0.9256\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0836 - accuracy: 0.9724 - val_loss: 0.2474 - val_accuracy: 0.9256\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0830 - accuracy: 0.9751 - val_loss: 0.1285 - val_accuracy: 0.9256\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0565 - accuracy: 0.9779 - val_loss: 0.3069 - val_accuracy: 0.9256\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0416 - accuracy: 0.9862 - val_loss: 0.3942 - val_accuracy: 0.8926\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 0.2008 - val_accuracy: 0.9091\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0485 - accuracy: 0.9834 - val_loss: 0.1590 - val_accuracy: 0.9421\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.2134 - val_accuracy: 0.9669\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.9807 - val_loss: 0.3826 - val_accuracy: 0.9669\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9972 - val_loss: 0.1808 - val_accuracy: 0.9421\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 0.1668 - val_accuracy: 0.9504\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0688 - accuracy: 0.9724 - val_loss: 0.2612 - val_accuracy: 0.9339\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0558 - accuracy: 0.9779 - val_loss: 0.0997 - val_accuracy: 0.9669\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9862 - val_loss: 0.1686 - val_accuracy: 0.9669\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9972 - val_loss: 0.3001 - val_accuracy: 0.9339\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.2302 - val_accuracy: 0.9587\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.1065 - val_accuracy: 0.9587\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9890 - val_loss: 0.5049 - val_accuracy: 0.9256\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0435 - accuracy: 0.9862 - val_loss: 0.1027 - val_accuracy: 0.9669\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0823 - val_accuracy: 0.9587\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9669\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.1100 - val_accuracy: 0.9669\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0108 - accuracy: 0.9945 - val_loss: 0.1107 - val_accuracy: 0.9587\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9752\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 0.1283 - val_accuracy: 0.9587\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1389 - val_accuracy: 0.9669\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.0812 - val_accuracy: 0.9752\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9890 - val_loss: 0.3246 - val_accuracy: 0.9504\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0390 - accuracy: 0.9890 - val_loss: 0.0738 - val_accuracy: 0.9835\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.0524 - accuracy: 0.9862 - val_loss: 0.0782 - val_accuracy: 0.9669\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.0539 - accuracy: 0.9751 - val_loss: 0.3496 - val_accuracy: 0.9504\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0792 - accuracy: 0.9696 - val_loss: 0.1005 - val_accuracy: 0.9669\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.1676 - accuracy: 0.9558 - val_loss: 0.2406 - val_accuracy: 0.9256\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.1333 - val_accuracy: 0.9669\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9669\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.1324 - val_accuracy: 0.9669\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9669\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9669\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 0.9972 - val_loss: 0.1151 - val_accuracy: 0.9587\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9752\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9752\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9669\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9669\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 0.9972 - val_loss: 0.1568 - val_accuracy: 0.9587\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9587\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.1137 - val_accuracy: 0.9504\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9862 - val_loss: 0.2919 - val_accuracy: 0.9504\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0932 - accuracy: 0.9807 - val_loss: 0.2380 - val_accuracy: 0.9256\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0724 - accuracy: 0.9834 - val_loss: 0.3969 - val_accuracy: 0.9174\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0642 - accuracy: 0.9834 - val_loss: 0.0461 - val_accuracy: 0.9917\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0805 - val_accuracy: 0.9752\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.0463 - val_accuracy: 0.9917\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.9972 - val_loss: 0.0797 - val_accuracy: 0.9917\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0634 - val_accuracy: 0.9835\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0273 - val_accuracy: 0.9917\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 0.0281 - val_accuracy: 0.9835\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9917\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9917\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9752\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9835\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 6.4474e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9917\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 0.9972 - val_loss: 0.0321 - val_accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9669\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9917\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9752\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 4.7999e-04 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9752\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 7.2120e-04 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9835\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.9972 - val_loss: 0.1147 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.3227e-04 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9669\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 8.5483e-04 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9669\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 9.8988e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 8.5643e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9752\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 7.8539e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9752\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 6.7140e-04 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.2565e-04 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9752\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.3106e-04 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9752\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.4317e-04 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9752\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.1714e-04 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9752\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9835\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 7.3762e-05 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9835\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.7746e-05 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 0.9835\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 0.9972 - val_loss: 0.2843 - val_accuracy: 0.9587\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.1633 - val_accuracy: 0.9752\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0320 - accuracy: 0.9862 - val_loss: 0.6528 - val_accuracy: 0.8926\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0568 - accuracy: 0.9890 - val_loss: 0.1344 - val_accuracy: 0.9669\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 0.2058 - val_accuracy: 0.9669\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.1849 - val_accuracy: 0.9587\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9972 - val_loss: 0.0342 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ffa0d5550>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_EDU = models.Sequential([\n",
    "    layers.Conv1D(16, kernel_size=5, activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(32, kernel_size=5, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(64, kernel_size=5, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "CNN_EDU.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "CNN_EDU.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN with LSTM layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{Neural Network Architecture: CBAM (Convolutional-Bidirectional LSTM with Attention Mechanism)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CBAM neural network is designed for the classification of human daily activities and fall behaviors. It combines convolutional layers, bidirectional LSTM layers, and an attention mechanism to enhance feature extraction and temporal modeling. The network structure is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
    "\\\\\n",
    "2. & \\text{Convolution Layer 1:} \\\\\n",
    "   & \\text{Contains 32 filters with a kernel size of 5 and uses the ReLU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2, strides of 2, and same padding.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Bidirectional LSTM Layer:} \\\\\n",
    "   & \\text{Consists of a bidirectional LSTM with 64 units, returning sequences to capture temporal dependencies in both directions.} \\\\\n",
    "\\\\\n",
    "5. & \\text{Flatten Layer:} \\\\\n",
    "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Dropout Layer:} \\\\\n",
    "   & \\text{Applies dropout with a probability of 0.5 to mitigate overfitting.} \\\\\n",
    "\\\\\n",
    "7. & \\text{Fully Connected Layer:} \\\\\n",
    "   & \\text{Contains 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CBAM model is trained using the Adam optimizer with a learning rate of 0.001. During training, the model is trained for 50 epochs with a batch size of 32. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
    "\n",
    "This CBAM neural network effectively combines convolutional and bidirectional LSTM layers with an attention mechanism to classify human activities and fall behaviors, capturing both spatial and temporal features from accelerometer and gyroscope data while addressing overfitting with dropout regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 7s 157ms/step - loss: 0.9334 - accuracy: 0.6464 - val_loss: 0.4515 - val_accuracy: 0.8430\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1984 - accuracy: 0.9282 - val_loss: 0.3700 - val_accuracy: 0.8347\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1075 - accuracy: 0.9641 - val_loss: 0.2603 - val_accuracy: 0.9256\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0586 - accuracy: 0.9807 - val_loss: 0.2073 - val_accuracy: 0.9339\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0445 - accuracy: 0.9917 - val_loss: 0.3603 - val_accuracy: 0.8926\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0358 - accuracy: 0.9862 - val_loss: 0.2079 - val_accuracy: 0.9421\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9587\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9421\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9587\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9587\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9587\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9504\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9421\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9421\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9421\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 9.7984e-04 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9421\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 9.5643e-04 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9421\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 8.9692e-04 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9421\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 7.3363e-04 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9421\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 7.2953e-04 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9504\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 6.6092e-04 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9504\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 5.6448e-04 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9504\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 5.6928e-04 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9504\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 5.4679e-04 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9504\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 4.5503e-04 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9504\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 4.5630e-04 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9504\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.9705e-04 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9504\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 4.2439e-04 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9587\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.1116e-04 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9587\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 3.0431e-04 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9587\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.9407e-04 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9669\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.7137e-04 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9669\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.3104e-04 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9587\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.3139e-04 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9587\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.2473e-04 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9587\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.2831e-04 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9669\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.8335e-04 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9669\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.6907e-04 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9669\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.4823e-04 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9669\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.4433e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9669\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.3657e-04 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9669\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.5420e-04 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9669\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.8063e-04 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9669\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1928e-04 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9752\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2734e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9669\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.2114e-04 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9669\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.1539e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9669\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 9.3693e-05 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9752\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.0710e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9752\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 9.7744e-05 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x250138454c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Sequential model for CBAM-IAM-CNN-BiLSTM\n",
    "CBAM = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=5, activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate\n",
    "CBAM.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "CBAM.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{Neural Network Architecture: CBAM-EDU (Convolutional-Bidirectional LSTM with Educational Enhancements)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CBAM-EDU neural network is designed for the classification of human daily activities and fall behaviors. It combines convolutional layers, bidirectional LSTM layers, and educational enhancements, including the GELU activation function, to improve feature extraction and temporal modeling. The network structure is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
    "\\\\\n",
    "2. & \\text{Convolution Layer 1:} \\\\\n",
    "   & \\text{Contains 16 filters with a kernel size of 5 and uses the GELU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer 1:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Convolution Layer 2:} \\\\\n",
    "   & \\text{Consists of 32 filters with a kernel size of 5 and employs the GELU activation function.} \\\\\n",
    "\\\\\n",
    "5. & \\text{MaxPooling Layer 2:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Convolution Layer 3:} \\\\\n",
    "   & \\text{Features 64 filters with a kernel size of 5 and uses the GELU activation function.} \\\\\n",
    "\\\\\n",
    "7. & \\text{MaxPooling Layer 3:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "8. & \\text{Convolution Layer 4:} \\\\\n",
    "   & \\text{Incorporates 128 filters with a kernel size of 5 and utilizes the GELU activation function.} \\\\\n",
    "\\\\\n",
    "9. & \\text{MaxPooling Layer 4:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "10. & \\text{MaxPooling Layer 5:} \\\\\n",
    "    & \\text{Performs max-pooling with a pool size of 2, strides of 2, and same padding.} \\\\\n",
    "\\\\\n",
    "11. & \\text{Bidirectional LSTM Layer:} \\\\\n",
    "    & \\text{Consists of a bidirectional LSTM with 64 units, returning sequences to capture temporal dependencies in both directions.} \\\\\n",
    "\\\\\n",
    "12. & \\text{Flatten Layer:} \\\\\n",
    "    & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "13. & \\text{Dropout Layer:} \\\\\n",
    "    & \\text{Applies dropout with a probability of 0.5 to mitigate overfitting.} \\\\\n",
    "\\\\\n",
    "14. & \\text{Fully Connected Layer:} \\\\\n",
    "    & \\text{Contains 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CBAM-EDU model is trained using the Adam optimizer with a learning rate of 0.001. During training, the model is trained for 50 epochs with a batch size of 32. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
    "\n",
    "This CBAM-EDU neural network effectively combines convolutional and bidirectional LSTM layers with educational enhancements, including the GELU activation function, to classify human activities and fall behaviors, capturing both spatial and temporal features from accelerometer and gyroscope data while addressing overfitting with dropout regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 3s 158ms/step - loss: 1.8378 - accuracy: 0.2320 - val_loss: 1.6560 - val_accuracy: 0.2893\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.4520 - accuracy: 0.4586 - val_loss: 1.3167 - val_accuracy: 0.4876\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9959 - accuracy: 0.5856 - val_loss: 0.8124 - val_accuracy: 0.7025\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6663 - accuracy: 0.7099 - val_loss: 0.5152 - val_accuracy: 0.8099\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4927 - accuracy: 0.7956 - val_loss: 0.3615 - val_accuracy: 0.8595\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3550 - accuracy: 0.8453 - val_loss: 0.3179 - val_accuracy: 0.8347\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3067 - accuracy: 0.8619 - val_loss: 0.2515 - val_accuracy: 0.9091\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2545 - accuracy: 0.9116 - val_loss: 0.2312 - val_accuracy: 0.8926\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2167 - accuracy: 0.8978 - val_loss: 0.2357 - val_accuracy: 0.8760\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1958 - accuracy: 0.9227 - val_loss: 0.1933 - val_accuracy: 0.9339\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1336 - accuracy: 0.9503 - val_loss: 0.1483 - val_accuracy: 0.9587\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1066 - accuracy: 0.9613 - val_loss: 0.1389 - val_accuracy: 0.9587\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0914 - accuracy: 0.9696 - val_loss: 0.1009 - val_accuracy: 0.9917\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0720 - accuracy: 0.9779 - val_loss: 0.1428 - val_accuracy: 0.9504\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.9917 - val_loss: 0.0926 - val_accuracy: 0.9669\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0393 - accuracy: 0.9917 - val_loss: 0.1205 - val_accuracy: 0.9504\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0355 - accuracy: 0.9917 - val_loss: 0.0805 - val_accuracy: 0.9917\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 0.0953 - val_accuracy: 0.9669\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0263 - accuracy: 0.9945 - val_loss: 0.1064 - val_accuracy: 0.9752\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9835\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.0852 - val_accuracy: 0.9835\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9669\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9752\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9835\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9835\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9917\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9917\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9917\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9917\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9917\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9917\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9917\n",
      "\n",
      "Reached target accuracy of 0.97, stopping training!\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Implement custom callback function for early stopping to prevent overfitting\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, target_accuracy=0.95, patience=10):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.target_accuracy = target_accuracy\n",
    "        self.patience = patience\n",
    "        self.stagnant_epochs = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_accuracy = logs.get('val_accuracy')\n",
    "        if current_accuracy is None:\n",
    "            raise ValueError(\"Validation accuracy is not available. Make sure you're using validation_data.\")\n",
    "        \n",
    "        if current_accuracy >= self.target_accuracy:\n",
    "            self.stagnant_epochs += 1\n",
    "            if self.stagnant_epochs >= self.patience:\n",
    "                self.model.stop_training = True\n",
    "                print(f\"\\nReached target accuracy of {self.target_accuracy}, stopping training!\")\n",
    "        else:\n",
    "            self.stagnant_epochs = 0\n",
    "\n",
    "custom_callback = CustomCallback(target_accuracy=0.97, patience=10)\n",
    "\n",
    "# Create the Sequential model for CBAM-IAM-CNN-BiLSTM\n",
    "CBAM_EDU = models.Sequential([\n",
    "    layers.Conv1D(16, kernel_size=5, activation='gelu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(32, kernel_size=5, activation='gelu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(64, kernel_size=5, activation='gelu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(128, kernel_size=5, activation='gelu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate\n",
    "CBAM_EDU.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = CBAM_EDU.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test), callbacks=[custom_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame({\"train_accuracy\": history.history[\"accuracy\"],\n",
    "                        \"val_accuracy\": history.history[\"val_accuracy\"],\n",
    "                        \"val_loss\": history.history[\"val_loss\"],\n",
    "                        \"train_loss\": history.history[\"val_loss\"],\n",
    "                        \"epoch\": np.arange(0, 42)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\engri\\Anaconda3\\envs\\deepl\\lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1089.12x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minimum = metrics[metrics.val_loss == metrics.val_loss.min()].epoch.values[0]\n",
    "maximum = metrics.val_loss.max()\n",
    "\n",
    "temp = pd.melt(metrics, id_vars=[\"epoch\"],\n",
    "                value_vars=['train_accuracy', 'val_accuracy', 'train_loss', 'val_loss'], var_name='Set', value_name='Score')\n",
    "\n",
    "temp['Metric'] = temp['Set'].apply(lambda x: x.split('_')[1].capitalize())\n",
    "temp['Set'] = temp['Set'].apply(lambda x: x.split('_')[0].capitalize())\n",
    "\n",
    "sns.set()\n",
    "rel = sns.relplot(temp, x=\"epoch\", y=\"Score\", col=\"Metric\", hue=\"Set\", kind=\"line\", facet_kws={'sharey': False, 'sharex': True})\n",
    "rel.fig.suptitle('Metrics', fontsize=18)\n",
    "rel.fig.subplots_adjust(top=.8)\n",
    "plt.axvline(minimum, color='red', linestyle=\"--\")\n",
    "plt.text(minimum+0.3, maximum, f'minimum eval loss\\nat {minimum} epochs', color=\"red\", fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyML PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the notebook follow the steps suggested by the [TinyML](https://tinymlbook.com/) book and use some of the code spread in the notebooks linked from the book itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to model files\n",
    "import os\n",
    "MODELS_DIR = 'models/'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = MODELS_DIR + 'model'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_34_layer_call_and_return_conditional_losses, lstm_cell_34_layer_call_fn, lstm_cell_35_layer_call_and_return_conditional_losses, lstm_cell_35_layer_call_fn, lstm_cell_34_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model\\assets\n"
     ]
    }
   ],
   "source": [
    "CBAM_EDU.save(MODEL_TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate a compressed (TFLite) model\n",
    "\n",
    "Once we've built a model with TensorFlow core, you can convert it to a smaller, more efficient ML model format called a TensorFlow Lite model.\n",
    "\n",
    "The first step is to generate models that are suitable for deployment on memory-constrained devices. We have already achieved an acceptable level of accuracy with our model. Now, we need to convert it into a specialized format that is space-efficient, especially considering it will be deployed on a microcontroller.\n",
    "\n",
    "#### Quantization\n",
    "One technique we employ to achieve this is called quantization. This process involves reducing the precision of the model's weights, and potentially the activations (output of each layer) as well. This reduction in precision leads to significant memory savings without compromising on accuracy. Moreover, quantized models tend to execute faster due to the simpler calculations required.\n",
    "\n",
    "In the upcoming cell, we will perform the model conversion twice: once with quantization and once without. This will allow us to compare the results and choose the most suitable version for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207568"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# To solve the issue related to TF Select log error!\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compressed vs original model performance\n",
    "\n",
    "To prove TFLite model is accurate even after conversion and quantization, we'll compare its predictions and loss on our test dataset.\n",
    "\n",
    "**Helper functions**\n",
    "\n",
    "We define the `predict` (for predictions) and `evaluate` (for loss) functions for TFLite models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tflite(tflite_model, x_test):\n",
    "  # Prepare the test data\n",
    "  x_test_ = x_test.copy()\n",
    "  x_test_ = x_test_.reshape((x_test.size, 1))\n",
    "  x_test_ = x_test_.astype(np.float32)\n",
    "\n",
    "  # Initialize the TFLite interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_content=tflite_model,\n",
    "                                    experimental_op_resolver_type=tf.lite.experimental.OpResolverType.BUILTIN_REF)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  # If required, quantize the input layer (from float to integer)\n",
    "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "  if (input_scale, input_zero_point) != (0.0, 0):\n",
    "    x_test_ = x_test_ / input_scale + input_zero_point\n",
    "    x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
    "  \n",
    "  # Invoke the interpreter\n",
    "  y_pred = np.empty(x_test_.size, dtype=output_details[\"dtype\"])\n",
    "  for i in range(len(x_test_)):\n",
    "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
    "    interpreter.invoke()\n",
    "    y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "  \n",
    "  # If required, dequantized the output layer (from integer to float)\n",
    "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "  if (output_scale, output_zero_point) != (0.0, 0):\n",
    "    y_pred = y_pred.astype(np.float32)\n",
    "    y_pred = (y_pred - output_zero_point) * output_scale\n",
    "\n",
    "  return y_pred\n",
    "\n",
    "def evaluate_tflite(tflite_model, x_test, y_true):\n",
    "  global model\n",
    "  y_pred = predict_tflite(tflite_model, x_test)\n",
    "  loss_function = tf.keras.losses.get(model.loss)\n",
    "  loss = loss_function(y_true, y_pred).numpy()\n",
    "  return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
