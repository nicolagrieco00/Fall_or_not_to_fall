{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7C-Td3lWvwF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.cluster import KMeans\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMikPly0WvwH",
        "outputId": "464ccf81-cf52-4b81-bb5d-fd01a2551c45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.list_physical_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxGlEaayWvwH",
        "outputId": "ecd47555-73cf-40c9-9781-a81b971dae79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ]
        }
      ],
      "source": [
        "gpu = tf.config.list_physical_devices('GPU')\n",
        "if gpu:\n",
        "  # only use the first GPU\n",
        "  try:\n",
        "    tf.config.experimental.set_visible_devices(gpu[0], 'GPU')\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpu), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "48-ZVmUZWvwI",
        "outputId": "8563e76a-9065-45bc-f253-880aad5beb89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-53da9adf-941b-40f1-9252-fd5ea2b4d495\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>xAcc</th>\n",
              "      <th>yAcc</th>\n",
              "      <th>zAcc</th>\n",
              "      <th>xGyro</th>\n",
              "      <th>yGyro</th>\n",
              "      <th>zGyro</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.99</td>\n",
              "      <td>-0.57</td>\n",
              "      <td>-7.28</td>\n",
              "      <td>-2.75</td>\n",
              "      <td>-3.23</td>\n",
              "      <td>2.62</td>\n",
              "      <td>fall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.51</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-6.93</td>\n",
              "      <td>-0.67</td>\n",
              "      <td>-6.35</td>\n",
              "      <td>4.64</td>\n",
              "      <td>fall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.22</td>\n",
              "      <td>-0.63</td>\n",
              "      <td>-6.73</td>\n",
              "      <td>0.79</td>\n",
              "      <td>-5.49</td>\n",
              "      <td>3.85</td>\n",
              "      <td>fall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.34</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-6.80</td>\n",
              "      <td>1.59</td>\n",
              "      <td>-2.26</td>\n",
              "      <td>0.67</td>\n",
              "      <td>fall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.49</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>-6.60</td>\n",
              "      <td>0.67</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>-1.10</td>\n",
              "      <td>fall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96795</th>\n",
              "      <td>7.30</td>\n",
              "      <td>-1.16</td>\n",
              "      <td>-4.58</td>\n",
              "      <td>18.19</td>\n",
              "      <td>3.60</td>\n",
              "      <td>-35.77</td>\n",
              "      <td>light</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96796</th>\n",
              "      <td>7.39</td>\n",
              "      <td>-0.37</td>\n",
              "      <td>-5.05</td>\n",
              "      <td>20.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-34.55</td>\n",
              "      <td>light</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96797</th>\n",
              "      <td>7.52</td>\n",
              "      <td>-1.46</td>\n",
              "      <td>-5.82</td>\n",
              "      <td>22.58</td>\n",
              "      <td>0.12</td>\n",
              "      <td>-28.02</td>\n",
              "      <td>light</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96798</th>\n",
              "      <td>7.58</td>\n",
              "      <td>-2.14</td>\n",
              "      <td>-6.31</td>\n",
              "      <td>19.47</td>\n",
              "      <td>2.44</td>\n",
              "      <td>-22.52</td>\n",
              "      <td>light</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96799</th>\n",
              "      <td>7.56</td>\n",
              "      <td>-1.90</td>\n",
              "      <td>-5.89</td>\n",
              "      <td>15.56</td>\n",
              "      <td>3.91</td>\n",
              "      <td>-19.23</td>\n",
              "      <td>light</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96800 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53da9adf-941b-40f1-9252-fd5ea2b4d495')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53da9adf-941b-40f1-9252-fd5ea2b4d495 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53da9adf-941b-40f1-9252-fd5ea2b4d495');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38cfb636-31d3-450d-9c79-761089b0fc27\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38cfb636-31d3-450d-9c79-761089b0fc27')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38cfb636-31d3-450d-9c79-761089b0fc27 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       xAcc  yAcc  zAcc  xGyro  yGyro  zGyro  label\n",
              "0      6.99 -0.57 -7.28  -2.75  -3.23   2.62   fall\n",
              "1      6.51 -0.75 -6.93  -0.67  -6.35   4.64   fall\n",
              "2      6.22 -0.63 -6.73   0.79  -5.49   3.85   fall\n",
              "3      6.34 -0.62 -6.80   1.59  -2.26   0.67   fall\n",
              "4      6.49 -0.39 -6.60   0.67  -0.24  -1.10   fall\n",
              "...     ...   ...   ...    ...    ...    ...    ...\n",
              "96795  7.30 -1.16 -4.58  18.19   3.60 -35.77  light\n",
              "96796  7.39 -0.37 -5.05  20.08   0.06 -34.55  light\n",
              "96797  7.52 -1.46 -5.82  22.58   0.12 -28.02  light\n",
              "96798  7.58 -2.14 -6.31  19.47   2.44 -22.52  light\n",
              "96799  7.56 -1.90 -5.89  15.56   3.91 -19.23  light\n",
              "\n",
              "[96800 rows x 7 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"data3.csv\")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z83gp2iEWvwI"
      },
      "outputs": [],
      "source": [
        "def split_resampling(data, seed=1218):\n",
        "    new_data = data.drop(\"label\",axis=1).to_numpy().reshape(-1, 400, 6)\n",
        "    labels = np.array(data.label.iloc[np.arange(0,data.shape[0], 400)])\n",
        "\n",
        "    sm = SMOTE(random_state=seed)\n",
        "    y = labels\n",
        "    X, y = sm.fit_resample(new_data.reshape(-1, 400*6), y)\n",
        "\n",
        "    # split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "    # scale\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train.reshape(-1, 400*6))\n",
        "    X_test = scaler.fit_transform(X_test.reshape(-1, 400*6))\n",
        "\n",
        "    # reshape\n",
        "    X_train = X_train.reshape(-1, 400, 6)\n",
        "    X_test = X_test.reshape(-1, 400, 6)\n",
        "    input_shape = X_train.shape[1:]\n",
        "    seq_len, n_features = input_shape\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    le.fit(np.unique(y_train))\n",
        "    y_train = le.transform(y_train)\n",
        "    y_test = le.transform(y_test)\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=7)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=7)\n",
        "\n",
        "    X_train = X_train.reshape(-1, seq_len, n_features)\n",
        "    X_test = X_test.reshape(-1, seq_len, n_features)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNO9J7UqWvwI"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, input_shape = split_resampling(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAF1-9DaWvwI",
        "outputId": "47336352-41f7-4312-d69a-8b6ff371eb6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(362, 400, 6)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li5u4gWSWvwI"
      },
      "source": [
        "# First CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPUdkpW4WvwJ"
      },
      "source": [
        "\\begin{align*}\n",
        "\\textbf{Neural Network Architecture: First CNN} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The CNN neural network is designed for the classification of human daily activities and fall behaviors. It is a relatively simple architecture with convolutional and fully connected layers. The network structure is as follows:\n",
        "\n",
        "\\begin{align*}\n",
        "1. & \\text{Input Layer:} \\\\\n",
        "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
        "\\\\\n",
        "2. & \\text{Convolution Layer:} \\\\\n",
        "   & \\text{Contains 32 filters with a kernel size of 3 and uses the ReLU activation function.} \\\\\n",
        "\\\\\n",
        "3. & \\text{MaxPooling Layer:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
        "\\\\\n",
        "4. & \\text{Flatten Layer:} \\\\\n",
        "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
        "\\\\\n",
        "5. & \\text{Fully Connected Layer 1:} \\\\\n",
        "   & \\text{Consists of 64 neurons with ReLU activation.} \\\\\n",
        "\\\\\n",
        "6. & \\text{Fully Connected Layer 2:} \\\\\n",
        "   & \\text{The output layer consists of 7 neurons with sigmoid activation, providing class probabilities.} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The First Model is trained using an appropriate optimizer, and the loss function is categorical cross-entropy. The performance of the model can be evaluated based on metrics such as accuracy.\n",
        "\n",
        "This simple First Model neural network is designed to classify human activities and fall behaviors effectively by extracting basic features from accelerometer and gyroscope data and producing class probabilities using a sigmoid activation function in the output layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVl6Z0-nWvwJ"
      },
      "outputs": [],
      "source": [
        "first_model = models.Sequential([\n",
        "    layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(7, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cuw1BtgRWvwJ"
      },
      "outputs": [],
      "source": [
        "first_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDkPRpLOWvwK",
        "outputId": "45000616-6ce5-4525-f846-74fd1b8ecdbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 398, 32)           608       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 199, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6368)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                407616    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 408,679\n",
            "Trainable params: 408,679\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "first_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNoCg6wmWvwK",
        "outputId": "1889dd58-b474-4e62-c2c9-3fc24c7dc258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 13s 52ms/step - loss: 1.0277 - accuracy: 0.6188 - val_loss: 0.6862 - val_accuracy: 0.7851\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1683 - accuracy: 0.9558 - val_loss: 0.3482 - val_accuracy: 0.8595\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9779 - val_loss: 0.1046 - val_accuracy: 0.9504\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 0.0880 - val_accuracy: 0.9669\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9752\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9752\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9752\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9752\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9752\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9752\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9752\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9752\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9752\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 9.3486e-04 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9752\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.5551e-04 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9752\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7.8521e-04 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9752\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7.2996e-04 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9752\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 6.7674e-04 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9752\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 6.2926e-04 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9752\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.8563e-04 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9752\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.4656e-04 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9752\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.1252e-04 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9752\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.8137e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.5405e-04 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9752\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.2704e-04 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9752\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.0487e-04 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9752\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.8143e-04 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9752\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.6180e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4323e-04 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.2582e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.1111e-04 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9752\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.9671e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.8408e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.7033e-04 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9752\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.5805e-04 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9752\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2.4793e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.3802e-04 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.2851e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.1973e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.1194e-04 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9752\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2.0387e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.9613e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.8907e-04 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9752\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.8247e-04 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9752\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.7619e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.7086e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.6489e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.5898e-04 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9752\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.5498e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.4941e-04 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9752\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x24d7f980c10>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w1rzXB-WvwK",
        "outputId": "8794dd90-e80c-439a-bc95-5a6de821c4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9752\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.05871253460645676, 0.9752066135406494]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZL1gLndWvwK"
      },
      "source": [
        "# CNN-HE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-HmQzdfWvwK"
      },
      "source": [
        "\\begin{align*}\n",
        "\\textbf{Neural Network Architecture: CNN-HE (Convolutional Neural Network with Heuristic Enhancements)} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The CNN-HE neural network is designed for the classification of human daily activities and fall behaviors. It utilizes convolutional layers and heuristic enhancements to improve accuracy in fall detection. The network structure consists of the following layers:\n",
        "\n",
        "\\begin{align*}\n",
        "1. & \\text{Input Layer:} \\\\\n",
        "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and inputs them into the convolution layer and bidirectional LSTM layer, respectively.} \\\\\n",
        "\\\\\n",
        "2. & \\text{Convolution Layer 1:} \\\\\n",
        "   & \\text{Performs 1D convolution with 32 filters, each with a kernel size of 5 and ReLU activation function.} \\\\\n",
        "\\\\\n",
        "3. & \\text{MaxPooling Layer 1:} \\\\\n",
        "   & \\text{Applies max-pooling with a pool size of 2 to perform subsampling.} \\\\\n",
        "\\\\\n",
        "4. & \\text{Convolution Layer 2:} \\\\\n",
        "   & \\text{Performs 1D convolution with 64 filters, each with a kernel size of 5 and ReLU activation function.} \\\\\n",
        "\\\\\n",
        "5. & \\text{MaxPooling Layer 2:} \\\\\n",
        "   & \\text{Applies max-pooling with a pool size of 2 to perform subsampling.} \\\\\n",
        "\\\\\n",
        "6. & \\text{Flatten Layer:} \\\\\n",
        "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
        "\\\\\n",
        "7. & \\text{Fully Connected Layer 1:} \\\\\n",
        "   & \\text{Consists of 512 neurons with ReLU activation function.} \\\\\n",
        "\\\\\n",
        "8. & \\text{Fully Connected Layer 2:} \\\\\n",
        "   & \\text{Consists of 7 neurons with softmax activation, which produces the final classification probabilities for 7 classes.} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The network is trained using the Adam optimizer with a categorical cross-entropy loss function. During training, the model is trained for 70 epochs with a batch size of 64. The model's performance is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
        "\n",
        "This CNN-HE neural network is designed to effectively classify human activities and fall behaviors by extracting meaningful features from accelerometer and gyroscope data and utilizing heuristic enhancements to improve the accuracy of fall detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ouXkqMjWvwK",
        "outputId": "8e9603ce-9662-4b8c-9c70-e1c211bb62cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "6/6 [==============================] - 2s 223ms/step - loss: 2.3598 - accuracy: 0.4033 - val_loss: 1.9100 - val_accuracy: 0.2810\n",
            "Epoch 2/70\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.8776 - accuracy: 0.7017 - val_loss: 0.6274 - val_accuracy: 0.8678\n",
            "Epoch 3/70\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.3119 - accuracy: 0.9641 - val_loss: 0.3448 - val_accuracy: 0.8926\n",
            "Epoch 4/70\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1115 - accuracy: 0.9751 - val_loss: 0.1847 - val_accuracy: 0.9504\n",
            "Epoch 5/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0410 - accuracy: 0.9917 - val_loss: 0.1053 - val_accuracy: 0.9587\n",
            "Epoch 6/70\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9504\n",
            "Epoch 7/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9587\n",
            "Epoch 8/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9504\n",
            "Epoch 9/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9504\n",
            "Epoch 10/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 9.2641e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9587\n",
            "Epoch 11/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 7.6219e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9587\n",
            "Epoch 12/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 6.2867e-04 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9587\n",
            "Epoch 13/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 5.5395e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9587\n",
            "Epoch 14/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 4.9596e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9587\n",
            "Epoch 15/70\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 4.5083e-04 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9587\n",
            "Epoch 16/70\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 4.1565e-04 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9587\n",
            "Epoch 17/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 3.8635e-04 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9587\n",
            "Epoch 18/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 3.6141e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9587\n",
            "Epoch 19/70\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.3989e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9587\n",
            "Epoch 20/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 3.1974e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9587\n",
            "Epoch 21/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 3.0113e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9587\n",
            "Epoch 22/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 2.8403e-04 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9587\n",
            "Epoch 23/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 2.6686e-04 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9587\n",
            "Epoch 24/70\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2.5345e-04 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9587\n",
            "Epoch 25/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 2.4098e-04 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9587\n",
            "Epoch 26/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 2.2799e-04 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9587\n",
            "Epoch 27/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 2.1725e-04 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9587\n",
            "Epoch 28/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 2.0657e-04 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9587\n",
            "Epoch 29/70\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 1.9642e-04 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9587\n",
            "Epoch 30/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 1.8515e-04 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9587\n",
            "Epoch 31/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1.7673e-04 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9587\n",
            "Epoch 32/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1.6806e-04 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9587\n",
            "Epoch 33/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1.6136e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9587\n",
            "Epoch 34/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.5310e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9587\n",
            "Epoch 35/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1.4707e-04 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9587\n",
            "Epoch 36/70\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.3963e-04 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9587\n",
            "Epoch 37/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.3388e-04 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9587\n",
            "Epoch 38/70\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 1.2848e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9669\n",
            "Epoch 39/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 1.2260e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9669\n",
            "Epoch 40/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1.1821e-04 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9669\n",
            "Epoch 41/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.1338e-04 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9669\n",
            "Epoch 42/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.0840e-04 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9669\n",
            "Epoch 43/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.0424e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9669\n",
            "Epoch 44/70\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.0048e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9669\n",
            "Epoch 45/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 9.6479e-05 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9669\n",
            "Epoch 46/70\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 9.2999e-05 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9669\n",
            "Epoch 47/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.9193e-05 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9669\n",
            "Epoch 48/70\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 8.5794e-05 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9669\n",
            "Epoch 49/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.2749e-05 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9669\n",
            "Epoch 50/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 7.9797e-05 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9669\n",
            "Epoch 51/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 7.6810e-05 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9669\n",
            "Epoch 52/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 7.4325e-05 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9669\n",
            "Epoch 53/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 7.1867e-05 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9669\n",
            "Epoch 54/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 6.9285e-05 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9669\n",
            "Epoch 55/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 6.6932e-05 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9669\n",
            "Epoch 56/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 6.4714e-05 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9669\n",
            "Epoch 57/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 6.2647e-05 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9669\n",
            "Epoch 58/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 6.0715e-05 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9669\n",
            "Epoch 59/70\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 5.8641e-05 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9669\n",
            "Epoch 60/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 5.7066e-05 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9669\n",
            "Epoch 61/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 5.5328e-05 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9669\n",
            "Epoch 62/70\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 5.3429e-05 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9669\n",
            "Epoch 63/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 5.1896e-05 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9669\n",
            "Epoch 64/70\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 5.0494e-05 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9669\n",
            "Epoch 65/70\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 4.8807e-05 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9669\n",
            "Epoch 66/70\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 4.7528e-05 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9669\n",
            "Epoch 67/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 4.6241e-05 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9669\n",
            "Epoch 68/70\n",
            "6/6 [==============================] - ETA: 0s - loss: 4.6496e-05 - accuracy: 1.00 - 0s 14ms/step - loss: 4.4881e-05 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9669\n",
            "Epoch 69/70\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 4.3633e-05 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9669\n",
            "Epoch 70/70\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 4.2484e-05 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9669\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x24ef833e340>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn_he = models.Sequential([\n",
        "    layers.Conv1D(32, kernel_size=5, activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Conv1D(64, kernel_size=5, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_he.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "cnn_he.fit(X_train, y_train, epochs=70, batch_size=64, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LK0pNDRWvwK"
      },
      "source": [
        "# CNN-3B3Conv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7k7137LWvwK"
      },
      "source": [
        "\\begin{align*}\n",
        "\\textbf{NN Architecture: CNN-3B3Conv (Convolutional Neural Network with Three Blocks of Three Convolutions)} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The CNN-3B3Conv neural network is designed for the classification of human daily activities and fall behaviors. It consists of three blocks, each containing three 1D convolutional layers with ReLU activation functions. The network structure is as follows:\n",
        "\n",
        "\\begin{align*}\n",
        "1. & \\text{Input Layer:} \\\\\n",
        "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
        "\\\\\n",
        "2. & \\text{Block 1:} \\\\\n",
        "   & \\text{Contains three 1D convolutional layers with 128 filters each and kernel sizes of 4. Each convolutional layer uses the ReLU activation function.} \\\\\n",
        "\\\\\n",
        "3. & \\text{MaxPooling Layer 1:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
        "\\\\\n",
        "4. & \\text{Block 2:} \\\\\n",
        "   & \\text{Similar to Block 1, contains three 1D convolutional layers with 128 filters each and kernel sizes of 3. All layers use ReLU activation functions.} \\\\\n",
        "\\\\\n",
        "5. & \\text{MaxPooling Layer 2:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
        "\\\\\n",
        "6. & \\text{Flatten Layer:} \\\\\n",
        "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
        "\\\\\n",
        "7. & \\text{Fully Connected Layer 1:} \\\\\n",
        "   & \\text{Consists of 128 neurons with ReLU activation.} \\\\\n",
        "\\\\\n",
        "8. & \\text{Dropout Layer:} \\\\\n",
        "   & \\text{Applies dropout with a probability of 0.5 to reduce overfitting.} \\\\\n",
        "\\\\\n",
        "9. & \\text{Fully Connected Layer 2:} \\\\\n",
        "   & \\text{Contains 64 neurons with ReLU activation.} \\\\\n",
        "\\\\\n",
        "10. & \\text{Fully Connected Layer 3:} \\\\\n",
        "    & \\text{The output layer consists of 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The CNN-3B3Conv model is trained using the Adam optimizer with categorical cross-entropy loss. During training, the model is trained for 20 epochs with a batch size of 64. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
        "\n",
        "This CNN-3B3Conv neural network is designed to classify human activities and fall behaviors effectively by leveraging three blocks of three convolutional layers to capture and extract relevant features from accelerometer and gyroscope data. The dropout layer helps prevent overfitting, enhancing the model's generalization ability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzUiz2IOWvwL",
        "outputId": "4db599ae-0e04-473d-dd16-77ea29517357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 3s 224ms/step - loss: 1.8915 - accuracy: 0.2707 - val_loss: 1.4394 - val_accuracy: 0.6694\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 1.2125 - accuracy: 0.5856 - val_loss: 0.8283 - val_accuracy: 0.7603\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.7969 - accuracy: 0.7017 - val_loss: 0.5928 - val_accuracy: 0.8512\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.5237 - accuracy: 0.7928 - val_loss: 0.4383 - val_accuracy: 0.8760\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.3553 - accuracy: 0.8591 - val_loss: 0.4250 - val_accuracy: 0.8760\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.2094 - accuracy: 0.9392 - val_loss: 0.2541 - val_accuracy: 0.9174\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.1785 - accuracy: 0.9392 - val_loss: 0.3014 - val_accuracy: 0.8843\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.1531 - accuracy: 0.9503 - val_loss: 0.2131 - val_accuracy: 0.9339\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0925 - accuracy: 0.9751 - val_loss: 0.1242 - val_accuracy: 0.9587\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0624 - accuracy: 0.9834 - val_loss: 0.1337 - val_accuracy: 0.9587\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.1949 - val_accuracy: 0.9421\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0503 - accuracy: 0.9862 - val_loss: 0.1856 - val_accuracy: 0.9669\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0314 - accuracy: 0.9862 - val_loss: 0.2174 - val_accuracy: 0.9587\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0416 - accuracy: 0.9862 - val_loss: 0.1986 - val_accuracy: 0.9421\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0518 - accuracy: 0.9834 - val_loss: 0.1888 - val_accuracy: 0.9421\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0335 - accuracy: 0.9890 - val_loss: 0.1471 - val_accuracy: 0.9669\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0460 - accuracy: 0.9890 - val_loss: 0.3576 - val_accuracy: 0.9008\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0417 - accuracy: 0.9890 - val_loss: 0.2213 - val_accuracy: 0.9421\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.0344 - accuracy: 0.9917 - val_loss: 0.1959 - val_accuracy: 0.9421\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.1954 - val_accuracy: 0.9504\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x24f22940a30>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CNN_3B3Conv = models.Sequential([\n",
        "    layers.Conv1D(128, kernel_size=4, activation='relu', input_shape=input_shape),\n",
        "    layers.Conv1D(128, kernel_size=4, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
        "    layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "    ])\n",
        "\n",
        "CNN_3B3Conv.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "CNN_3B3Conv.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubq4gilVWvwL"
      },
      "source": [
        "# CNN EDU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5NZy9m_WvwL"
      },
      "source": [
        "\\begin{align*}\n",
        "\\textbf{Neural Network Architecture: CNN-EDU (Convolutional Neural Network with Educational Enhancements)} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The CNN-EDU neural network is designed for the classification of human daily activities and fall behaviors. It features an architecture with multiple convolutional layers and educational enhancements to improve its performance. The network structure is as follows:\n",
        "\n",
        "\\begin{align*}\n",
        "1. & \\text{Input Layer:} \\\\\n",
        "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
        "\\\\\n",
        "2. & \\text{Convolution Layer 1:} \\\\\n",
        "   & \\text{Contains 16 filters with a kernel size of 5 and uses the ReLU activation function.} \\\\\n",
        "\\\\\n",
        "3. & \\text{MaxPooling Layer 1:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
        "\\\\\n",
        "4. & \\text{Convolution Layer 2:} \\\\\n",
        "   & \\text{Consists of 32 filters with a kernel size of 5 and employs ReLU activation.} \\\\\n",
        "\\\\\n",
        "5. & \\text{MaxPooling Layer 2:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
        "\\\\\n",
        "6. & \\text{Convolution Layer 3:} \\\\\n",
        "   & \\text{Features 64 filters with a kernel size of 5 and ReLU activation.} \\\\\n",
        "\\\\\n",
        "7. & \\text{MaxPooling Layer 3:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
        "\\\\\n",
        "8. & \\text{Convolution Layer 4:} \\\\\n",
        "   & \\text{Incorporates 128 filters with a kernel size of 5 and ReLU activation.} \\\\\n",
        "\\\\\n",
        "9. & \\text{MaxPooling Layer 4:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
        "\\\\\n",
        "10. & \\text{Flatten Layer:} \\\\\n",
        "    & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
        "\\\\\n",
        "11. & \\text{Fully Connected Layer 1:} \\\\\n",
        "    & \\text{Consists of 128 neurons with ReLU activation.} \\\\\n",
        "\\\\\n",
        "12. & \\text{Dropout Layer:} \\\\\n",
        "    & \\text{Applies dropout with a probability of 0.5 to mitigate overfitting.} \\\\\n",
        "\\\\\n",
        "13. & \\text{Fully Connected Layer 2:} \\\\\n",
        "    & \\text{Contains 64 neurons with ReLU activation.} \\\\\n",
        "\\\\\n",
        "14. & \\text{Fully Connected Layer 3:} \\\\\n",
        "    & \\text{The output layer consists of 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The CNN-EDU model is trained using the Adam optimizer with categorical cross-entropy loss. During training, the model is trained for 100 epochs with a batch size of 16. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
        "\n",
        "This CNN-EDU neural network leverages multiple convolutional layers and educational enhancements to effectively classify human activities and fall behaviors by extracting meaningful features from accelerometer and gyroscope data while reducing overfitting through dropout regularization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d2Uvb45WvwL",
        "outputId": "66d80743-bd69-43ff-b508-ca4ffb7e0fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 1.7035 - accuracy: 0.3260 - val_loss: 1.0621 - val_accuracy: 0.7025\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 1.0431 - accuracy: 0.5580 - val_loss: 0.6676 - val_accuracy: 0.7851\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6129 - accuracy: 0.7541 - val_loss: 0.4409 - val_accuracy: 0.8430\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.4159 - accuracy: 0.8481 - val_loss: 0.4282 - val_accuracy: 0.8760\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.4067 - accuracy: 0.8591 - val_loss: 0.4576 - val_accuracy: 0.7851\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3326 - accuracy: 0.9006 - val_loss: 0.2293 - val_accuracy: 0.9339\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1728 - accuracy: 0.9448 - val_loss: 0.1903 - val_accuracy: 0.9421\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.1556 - accuracy: 0.9365 - val_loss: 0.2533 - val_accuracy: 0.8512\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.1681 - accuracy: 0.9392 - val_loss: 0.1577 - val_accuracy: 0.9174\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0738 - accuracy: 0.9834 - val_loss: 0.2303 - val_accuracy: 0.9339\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0807 - accuracy: 0.9696 - val_loss: 0.2050 - val_accuracy: 0.9256\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0836 - accuracy: 0.9724 - val_loss: 0.2474 - val_accuracy: 0.9256\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0830 - accuracy: 0.9751 - val_loss: 0.1285 - val_accuracy: 0.9256\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0565 - accuracy: 0.9779 - val_loss: 0.3069 - val_accuracy: 0.9256\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0416 - accuracy: 0.9862 - val_loss: 0.3942 - val_accuracy: 0.8926\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 0.2008 - val_accuracy: 0.9091\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0485 - accuracy: 0.9834 - val_loss: 0.1590 - val_accuracy: 0.9421\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.2134 - val_accuracy: 0.9669\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.9807 - val_loss: 0.3826 - val_accuracy: 0.9669\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9972 - val_loss: 0.1808 - val_accuracy: 0.9421\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 0.1668 - val_accuracy: 0.9504\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0688 - accuracy: 0.9724 - val_loss: 0.2612 - val_accuracy: 0.9339\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0558 - accuracy: 0.9779 - val_loss: 0.0997 - val_accuracy: 0.9669\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9862 - val_loss: 0.1686 - val_accuracy: 0.9669\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9972 - val_loss: 0.3001 - val_accuracy: 0.9339\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.2302 - val_accuracy: 0.9587\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.1065 - val_accuracy: 0.9587\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9890 - val_loss: 0.5049 - val_accuracy: 0.9256\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0435 - accuracy: 0.9862 - val_loss: 0.1027 - val_accuracy: 0.9669\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0823 - val_accuracy: 0.9587\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9669\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.1100 - val_accuracy: 0.9669\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0108 - accuracy: 0.9945 - val_loss: 0.1107 - val_accuracy: 0.9587\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9752\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 0.1283 - val_accuracy: 0.9587\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1389 - val_accuracy: 0.9669\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.0812 - val_accuracy: 0.9752\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9890 - val_loss: 0.3246 - val_accuracy: 0.9504\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0390 - accuracy: 0.9890 - val_loss: 0.0738 - val_accuracy: 0.9835\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0524 - accuracy: 0.9862 - val_loss: 0.0782 - val_accuracy: 0.9669\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0539 - accuracy: 0.9751 - val_loss: 0.3496 - val_accuracy: 0.9504\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0792 - accuracy: 0.9696 - val_loss: 0.1005 - val_accuracy: 0.9669\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.1676 - accuracy: 0.9558 - val_loss: 0.2406 - val_accuracy: 0.9256\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.1333 - val_accuracy: 0.9669\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9669\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.1324 - val_accuracy: 0.9669\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9669\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9669\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 0.9972 - val_loss: 0.1151 - val_accuracy: 0.9587\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9752\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9752\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9752\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9669\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9669\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 0.9972 - val_loss: 0.1568 - val_accuracy: 0.9587\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9587\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.1137 - val_accuracy: 0.9504\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9862 - val_loss: 0.2919 - val_accuracy: 0.9504\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0932 - accuracy: 0.9807 - val_loss: 0.2380 - val_accuracy: 0.9256\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0724 - accuracy: 0.9834 - val_loss: 0.3969 - val_accuracy: 0.9174\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0642 - accuracy: 0.9834 - val_loss: 0.0461 - val_accuracy: 0.9917\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0805 - val_accuracy: 0.9752\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.0463 - val_accuracy: 0.9917\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.9972 - val_loss: 0.0797 - val_accuracy: 0.9917\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0634 - val_accuracy: 0.9835\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0273 - val_accuracy: 0.9917\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 0.0281 - val_accuracy: 0.9835\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9917\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9917\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9752\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9835\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 6.4474e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9917\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 0.9972 - val_loss: 0.0321 - val_accuracy: 0.9917\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9669\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9917\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9752\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 4.7999e-04 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9752\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 7.2120e-04 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9835\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.9972 - val_loss: 0.1147 - val_accuracy: 0.9752\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 4.3227e-04 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9669\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 8.5483e-04 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9669\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 9.8988e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9752\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 8.5643e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9752\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 7.8539e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9752\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 6.7140e-04 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9752\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 1.2565e-04 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9752\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 1.3106e-04 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9752\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 1.4317e-04 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9752\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 2.1714e-04 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9752\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9835\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 7.3762e-05 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9835\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 4.7746e-05 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 0.9835\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 0.9972 - val_loss: 0.2843 - val_accuracy: 0.9587\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.1633 - val_accuracy: 0.9752\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0320 - accuracy: 0.9862 - val_loss: 0.6528 - val_accuracy: 0.8926\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0568 - accuracy: 0.9890 - val_loss: 0.1344 - val_accuracy: 0.9669\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 0.2058 - val_accuracy: 0.9669\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.1849 - val_accuracy: 0.9587\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9972 - val_loss: 0.0342 - val_accuracy: 0.9917\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x24ffa0d5550>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CNN_EDU = models.Sequential([\n",
        "    layers.Conv1D(16, kernel_size=5, activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Conv1D(32, kernel_size=5, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Conv1D(64, kernel_size=5, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Conv1D(128, kernel_size=5, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "CNN_EDU.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "CNN_EDU.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w4Ms63ZWvwL"
      },
      "source": [
        "# NN with LSTM layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mExej7hTWvwL"
      },
      "source": [
        "\\begin{align*}\n",
        "\\textbf{Neural Network Architecture: CBAM (Convolutional-Bidirectional LSTM with Attention Mechanism)} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The CBAM neural network is designed for the classification of human daily activities and fall behaviors. It combines convolutional layers, bidirectional LSTM layers, and an attention mechanism to enhance feature extraction and temporal modeling. The network structure is as follows:\n",
        "\n",
        "\\begin{align*}\n",
        "1. & \\text{Input Layer:} \\\\\n",
        "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
        "\\\\\n",
        "2. & \\text{Convolution Layer 1:} \\\\\n",
        "   & \\text{Contains 32 filters with a kernel size of 5 and uses the ReLU activation function.} \\\\\n",
        "\\\\\n",
        "3. & \\text{MaxPooling Layer:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2, strides of 2, and same padding.} \\\\\n",
        "\\\\\n",
        "4. & \\text{Bidirectional LSTM Layer:} \\\\\n",
        "   & \\text{Consists of a bidirectional LSTM with 64 units, returning sequences to capture temporal dependencies in both directions.} \\\\\n",
        "\\\\\n",
        "5. & \\text{Flatten Layer:} \\\\\n",
        "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
        "\\\\\n",
        "6. & \\text{Dropout Layer:} \\\\\n",
        "   & \\text{Applies dropout with a probability of 0.5 to mitigate overfitting.} \\\\\n",
        "\\\\\n",
        "7. & \\text{Fully Connected Layer:} \\\\\n",
        "   & \\text{Contains 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The CBAM model is trained using the Adam optimizer with a learning rate of 0.001. During training, the model is trained for 50 epochs with a batch size of 32. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
        "\n",
        "This CBAM neural network effectively combines convolutional and bidirectional LSTM layers with an attention mechanism to classify human activities and fall behaviors, capturing both spatial and temporal features from accelerometer and gyroscope data while addressing overfitting with dropout regularization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQDbmdJBWvwL",
        "outputId": "07fc2178-0e9f-4adb-ffdc-1d69a6b16e3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 7s 157ms/step - loss: 0.9334 - accuracy: 0.6464 - val_loss: 0.4515 - val_accuracy: 0.8430\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 0.1984 - accuracy: 0.9282 - val_loss: 0.3700 - val_accuracy: 0.8347\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 0.1075 - accuracy: 0.9641 - val_loss: 0.2603 - val_accuracy: 0.9256\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 0.0586 - accuracy: 0.9807 - val_loss: 0.2073 - val_accuracy: 0.9339\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.0445 - accuracy: 0.9917 - val_loss: 0.3603 - val_accuracy: 0.8926\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.0358 - accuracy: 0.9862 - val_loss: 0.2079 - val_accuracy: 0.9421\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9587\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9421\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9587\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9587\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9587\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9504\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9421\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9421\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9421\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 9.7984e-04 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9421\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 9.5643e-04 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9421\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 8.9692e-04 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9421\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 7.3363e-04 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9421\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 7.2953e-04 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9504\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 6.6092e-04 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9504\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 5.6448e-04 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9504\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 5.6928e-04 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9504\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 5.4679e-04 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9504\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 4.5503e-04 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9504\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 4.5630e-04 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9504\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 3.9705e-04 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9504\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 4.2439e-04 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9587\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 3.1116e-04 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9587\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 3.0431e-04 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9587\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2.9407e-04 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9669\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2.7137e-04 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9669\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2.3104e-04 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9587\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2.3139e-04 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9587\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2.2473e-04 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9587\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2.2831e-04 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9669\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1.8335e-04 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9669\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1.6907e-04 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9669\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1.4823e-04 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9669\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1.4433e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9669\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1.3657e-04 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9669\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1.5420e-04 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9669\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1.8063e-04 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9669\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1.1928e-04 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9752\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1.2734e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9669\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1.2114e-04 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9669\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1.1539e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9669\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 9.3693e-05 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9752\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1.0710e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9752\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 9.7744e-05 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9752\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x250138454c0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the Sequential model for CBAM-IAM-CNN-BiLSTM\n",
        "CBAM = models.Sequential([\n",
        "    layers.Conv1D(32, kernel_size=5, activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
        "    layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate\n",
        "CBAM.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "CBAM.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXU3lTmRWvwL"
      },
      "source": [
        "# Best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxDW0I92WvwM"
      },
      "source": [
        "\\begin{align*}\n",
        "\\textbf{Neural Network Architecture: CBAM-EDU (Convolutional-Bidirectional LSTM with Educational Enhancements)} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The CBAM-EDU neural network is designed for the classification of human daily activities and fall behaviors. It combines convolutional layers, bidirectional LSTM layers, and educational enhancements, including the GELU activation function, to improve feature extraction and temporal modeling. The network structure is as follows:\n",
        "\n",
        "\\begin{align*}\n",
        "1. & \\text{Input Layer:} \\\\\n",
        "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
        "\\\\\n",
        "2. & \\text{Convolution Layer 1:} \\\\\n",
        "   & \\text{Contains 16 filters with a kernel size of 5 and uses the GELU activation function.} \\\\\n",
        "\\\\\n",
        "3. & \\text{MaxPooling Layer 1:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
        "\\\\\n",
        "4. & \\text{Convolution Layer 2:} \\\\\n",
        "   & \\text{Consists of 32 filters with a kernel size of 5 and employs the GELU activation function.} \\\\\n",
        "\\\\\n",
        "5. & \\text{MaxPooling Layer 2:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
        "\\\\\n",
        "6. & \\text{Convolution Layer 3:} \\\\\n",
        "   & \\text{Features 64 filters with a kernel size of 5 and uses the GELU activation function.} \\\\\n",
        "\\\\\n",
        "7. & \\text{MaxPooling Layer 3:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
        "\\\\\n",
        "8. & \\text{Convolution Layer 4:} \\\\\n",
        "   & \\text{Incorporates 128 filters with a kernel size of 5 and utilizes the GELU activation function.} \\\\\n",
        "\\\\\n",
        "9. & \\text{MaxPooling Layer 4:} \\\\\n",
        "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
        "\\\\\n",
        "10. & \\text{MaxPooling Layer 5:} \\\\\n",
        "    & \\text{Performs max-pooling with a pool size of 2, strides of 2, and same padding.} \\\\\n",
        "\\\\\n",
        "11. & \\text{Bidirectional LSTM Layer:} \\\\\n",
        "    & \\text{Consists of a bidirectional LSTM with 64 units, returning sequences to capture temporal dependencies in both directions.} \\\\\n",
        "\\\\\n",
        "12. & \\text{Flatten Layer:} \\\\\n",
        "    & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
        "\\\\\n",
        "13. & \\text{Dropout Layer:} \\\\\n",
        "    & \\text{Applies dropout with a probability of 0.5 to mitigate overfitting.} \\\\\n",
        "\\\\\n",
        "14. & \\text{Fully Connected Layer:} \\\\\n",
        "    & \\text{Contains 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "The CBAM-EDU model is trained using the Adam optimizer with a learning rate of 0.001. During training, the model is trained for 50 epochs with a batch size of 32. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
        "\n",
        "This CBAM-EDU neural network effectively combines convolutional and bidirectional LSTM layers with educational enhancements, including the GELU activation function, to classify human activities and fall behaviors, capturing both spatial and temporal features from accelerometer and gyroscope data while addressing overfitting with dropout regularization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqrLr3gIWvwM",
        "outputId": "27159ea0-ff00-4f81-feac-237ed0ff2da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 17s 242ms/step - loss: 1.8392 - accuracy: 0.1906 - val_loss: 1.6706 - val_accuracy: 0.1488\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 1.5236 - accuracy: 0.4061 - val_loss: 1.2051 - val_accuracy: 0.7438\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.9618 - accuracy: 0.7017 - val_loss: 0.6232 - val_accuracy: 0.7521\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4920 - accuracy: 0.8287 - val_loss: 0.3898 - val_accuracy: 0.8595\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4194 - accuracy: 0.7818 - val_loss: 0.3211 - val_accuracy: 0.8926\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3771 - accuracy: 0.8370 - val_loss: 0.2825 - val_accuracy: 0.9091\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3295 - accuracy: 0.8536 - val_loss: 0.2654 - val_accuracy: 0.8760\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2690 - accuracy: 0.8646 - val_loss: 0.2186 - val_accuracy: 0.9174\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2258 - accuracy: 0.9171 - val_loss: 0.1848 - val_accuracy: 0.9504\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1708 - accuracy: 0.9365 - val_loss: 0.1613 - val_accuracy: 0.9504\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1461 - accuracy: 0.9420 - val_loss: 0.1433 - val_accuracy: 0.9421\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1110 - accuracy: 0.9586 - val_loss: 0.1364 - val_accuracy: 0.9421\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0983 - accuracy: 0.9613 - val_loss: 0.1062 - val_accuracy: 0.9752\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0723 - accuracy: 0.9724 - val_loss: 0.0849 - val_accuracy: 0.9752\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0532 - accuracy: 0.9890 - val_loss: 0.0493 - val_accuracy: 0.9917\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0363 - accuracy: 0.9917 - val_loss: 0.0656 - val_accuracy: 0.9669\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 0.0396 - val_accuracy: 0.9917\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9669\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0214 - accuracy: 0.9972 - val_loss: 0.0494 - val_accuracy: 0.9835\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.0417 - val_accuracy: 0.9752\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9587\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9835\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0398 - val_accuracy: 0.9835\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9835\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0141 - accuracy: 0.9917 - val_loss: 0.1003 - val_accuracy: 0.9587\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9917\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9835\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.0357 - val_accuracy: 0.9835\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9752\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 0.9752\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9917\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9917\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9835\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9835\n",
            "Epoch 35/200\n",
            "1/6 [====>.........................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Reached target accuracy of 0.97, stopping training!\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9835\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 200\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Implement custom callback function for early stopping to prevent overfitting\n",
        "\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, target_accuracy=0.95, patience=10):\n",
        "        super(CustomCallback, self).__init__()\n",
        "        self.target_accuracy = target_accuracy\n",
        "        self.patience = patience\n",
        "        self.stagnant_epochs = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current_accuracy = logs.get('val_accuracy')\n",
        "        if current_accuracy is None:\n",
        "            raise ValueError(\"Validation accuracy is not available. Make sure you're using validation_data.\")\n",
        "\n",
        "        if current_accuracy >= self.target_accuracy:\n",
        "            self.stagnant_epochs += 1\n",
        "            if self.stagnant_epochs >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "                print(f\"\\nReached target accuracy of {self.target_accuracy}, stopping training!\")\n",
        "        else:\n",
        "            self.stagnant_epochs = 0\n",
        "\n",
        "custom_callback = CustomCallback(target_accuracy=0.97, patience=10)\n",
        "\n",
        "# Create the Sequential model for CBAM-IAM-CNN-BiLSTM\n",
        "CBAM_EDU = models.Sequential([\n",
        "    layers.Conv1D(16, kernel_size=5, activation='gelu', input_shape=input_shape),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Conv1D(32, kernel_size=5, activation='gelu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Conv1D(64, kernel_size=5, activation='gelu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Conv1D(128, kernel_size=5, activation='gelu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
        "    layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate\n",
        "CBAM_EDU.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = CBAM_EDU.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test), callbacks=[custom_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6dFCzADWvwM"
      },
      "source": [
        "# Show results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsIvR-GPWvwM"
      },
      "outputs": [],
      "source": [
        "metrics = pd.DataFrame({\"train_accuracy\": history.history[\"accuracy\"],\n",
        "                        \"val_accuracy\": history.history[\"val_accuracy\"],\n",
        "                        \"val_loss\": history.history[\"val_loss\"],\n",
        "                        \"train_loss\": history.history[\"val_loss\"],\n",
        "                        \"epoch\": np.arange(0, 169)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_JTESnFWvwM",
        "outputId": "48c01ddb-54f2-4729-f375-67afce2f36f6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1089.12x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "minimum = metrics[metrics.val_loss == metrics.val_loss.min()].epoch.values[0]\n",
        "maximum = metrics.val_loss.max()\n",
        "\n",
        "temp = pd.melt(metrics, id_vars=[\"epoch\"],\n",
        "                value_vars=['train_accuracy', 'val_accuracy', 'train_loss', 'val_loss'], var_name='Set', value_name='Score')\n",
        "\n",
        "temp['Metric'] = temp['Set'].apply(lambda x: x.split('_')[1].capitalize())\n",
        "temp['Set'] = temp['Set'].apply(lambda x: x.split('_')[0].capitalize())\n",
        "\n",
        "sns.set()\n",
        "rel = sns.relplot(temp, x=\"epoch\", y=\"Score\", col=\"Metric\", hue=\"Set\", kind=\"line\", facet_kws={'sharey': False, 'sharex': True})\n",
        "rel.fig.suptitle('Metrics', fontsize=18)\n",
        "rel.fig.subplots_adjust(top=.8)\n",
        "plt.axvline(minimum, color='red', linestyle=\"--\")\n",
        "plt.text(minimum+0.3, maximum, f'minimum eval loss\\nat {minimum} epochs', color=\"red\", fontsize = 10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSJSLDuuWvwM"
      },
      "source": [
        "# TinyML PIPELINE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAAV9Ac2WvwM"
      },
      "source": [
        "In this part of the notebook follow the steps suggested by the [TinyML](https://tinymlbook.com/) book and use some of the code spread in the notebooks linked from the book itself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnJxtW3rWvwM"
      },
      "outputs": [],
      "source": [
        "# Define paths to model files\n",
        "import os\n",
        "MODELS_DIR = 'models/'\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.mkdir(MODELS_DIR)\n",
        "MODEL_TF = MODELS_DIR + 'model'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
        "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
        "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvrZmGriWvwM"
      },
      "outputs": [],
      "source": [
        "CBAM_EDU.save(MODEL_TF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh_e-lXRWvwN"
      },
      "source": [
        "## 1. Generate a compressed (TFLite) model\n",
        "\n",
        "Once we've built a model with TensorFlow core, you can convert it to a smaller, more efficient ML model format called a TensorFlow Lite model.\n",
        "\n",
        "The first step is to generate models that are suitable for deployment on memory-constrained devices. We have already achieved an acceptable level of accuracy with our model. Now, we need to convert it into a specialized format that is space-efficient, especially considering it will be deployed on a microcontroller.\n",
        "\n",
        "#### Quantization\n",
        "One technique we employ to achieve this is called quantization. This process involves reducing the precision of the model's weights, and potentially the activations (output of each layer) as well. This reduction in precision leads to significant memory savings without compromising on accuracy. Moreover, quantized models tend to execute faster due to the simpler calculations required.\n",
        "\n",
        "In the upcoming cell, we will perform the model conversion twice: once with quantization and once without. This will allow us to compare the results and choose the most suitable version for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJzukTTZWvwN",
        "outputId": "f829ecf2-8553-4fa1-aaf8-f18b36d32d84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200664"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
        "\n",
        "X_train = X_train.astype(dtype=\"float32\")\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "def representative_dataset():\n",
        "  for i in range(100):\n",
        "    yield([X_train[i].reshape(1,400, 6)])\n",
        "\n",
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# To solve the issue related to TF Select log error!\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS_INT8, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "\n",
        "converter.representative_dataset = representative_dataset\n",
        "\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9sz_mYhWvwN"
      },
      "source": [
        "### 2. Compressed vs original model performance\n",
        "\n",
        "To prove TFLite model is accurate even after conversion and quantization, we'll compare its predictions and loss on our test dataset.\n",
        "\n",
        "**Helper functions**\n",
        "\n",
        "We define the `predict` (for predictions) and `evaluate` (for loss) functions for TFLite models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bedELHOWvwT",
        "outputId": "b7f333f9-0343-45e3-df16-11c9fe4b32f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 400, 6)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMiv0s7gWvwT",
        "outputId": "ee92cea8-e826-4801-f600-3f4e53482164"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2400"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "121*400*6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKID5l1aWvwU"
      },
      "outputs": [],
      "source": [
        "def create_one_hot_vector(x):\n",
        "\n",
        "    \"\"\"\n",
        "    Create a one-hot vector with a 1 at the given index.\n",
        "\n",
        "    Parameters:\n",
        "        index (int): Index where the 1 should be placed.\n",
        "        size (int): Size of the resulting array.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: One-hot vector.\n",
        "    \"\"\"\n",
        "    index = np.argmax(x)\n",
        "\n",
        "    result = np.zeros(x.shape[0])\n",
        "    result[index] = 1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-HTZghGWvwU"
      },
      "outputs": [],
      "source": [
        "def predict_tflite(tflite_model, x_test):\n",
        "  # Prepare the test data\n",
        "  x_test_ = x_test.copy()\n",
        "  x_test_ = x_test_.reshape((x_test.shape[0],400, 6))\n",
        "  x_test_ = x_test_.astype(np.float32)\n",
        "\n",
        "  # Initialize the TFLite interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  # If required, quantize the input layer (from float to integer)\n",
        "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "  if (input_scale, input_zero_point) != (0.0, 0):\n",
        "    x_test_ = x_test_ / input_scale + input_zero_point\n",
        "    x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
        "\n",
        "  # Invoke the interpreter\n",
        "  y_pred = np.empty((x_test_.shape[0],7), dtype=output_details[\"dtype\"])\n",
        "  for i in range(len(x_test_)):\n",
        "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
        "    interpreter.invoke()\n",
        "    y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "  # If required, dequantized the output layer (from integer to float)\n",
        "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "  if (output_scale, output_zero_point) != (0.0, 0):\n",
        "    y_pred = y_pred.astype(np.float32)\n",
        "    y_pred = (y_pred - output_zero_point) * output_scale\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "def evaluate_tflite(tflite_model, x_test, y_true):\n",
        "  global CBAM_EDU\n",
        "  y_pred = predict_tflite(tflite_model, x_test)\n",
        "  loss_function = tf.keras.losses.get(CBAM_EDU.loss)\n",
        "  loss = loss_function(y_true, y_pred).numpy()\n",
        "  y_pred_class = np.apply_along_axis(create_one_hot_vector, 1, y_pred)\n",
        "  acc = accuracy_score(y_true,y_pred_class)\n",
        "  return loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w3sJIk8WvwU"
      },
      "outputs": [],
      "source": [
        "loss_tf_lite , acc_tf_lite= evaluate_tflite(model_tflite,X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6wJfePcWvwU"
      },
      "source": [
        "### 3. Generate a TensorFlow Lite for Microcontrollers Model\n",
        "Convert the TensorFlow Lite quantized model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU8_mepSYA-A"
      },
      "outputs": [],
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "!echo \"const unsigned char model[] = {\" > /content/models/model.h\n",
        "!cat models/model.tflite | xxd -i      >> /content/models/model.h\n",
        "!echo \"};\"                              >> /content/models/model.h"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
